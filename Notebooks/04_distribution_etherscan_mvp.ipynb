{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbedc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3353ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.read_csv(\"config/token_master.csv\")\n",
    "\n",
    "with open(\"config/secrets.json\", \"r\") as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "ETHERSCAN_API_KEY = secrets[\"ETHERSCAN_API_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfbed0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Helper Functions (Etherscan v2)\n",
    "# ===============================\n",
    "\n",
    "ETHERSCAN_BASE = \"https://api.etherscan.io/v2/api\"\n",
    "ETH_CHAIN_ID = 1  # Ethereum mainnet\n",
    "\n",
    "\n",
    "# ---- Address validation ----\n",
    "def is_valid_eth_address(addr: str) -> bool:\n",
    "    if not isinstance(addr, str):\n",
    "        return False\n",
    "    a = addr.strip()\n",
    "    return a.startswith(\"0x\") and len(a) == 42\n",
    "\n",
    "\n",
    "# ---- Etherscan request wrapper (v2-safe) ----\n",
    "def es_get(params, base_sleep=0.35, max_retries=6):\n",
    "    \"\"\"\n",
    "    Robust Etherscan API v2 GET with retry & rate-limit handling\n",
    "    \"\"\"\n",
    "    params = dict(params)\n",
    "    params[\"apikey\"] = ETHERSCAN_API_KEY\n",
    "    params[\"chainid\"] = ETH_CHAIN_ID\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        r = requests.get(ETHERSCAN_BASE, params=params, timeout=30)\n",
    "\n",
    "        if r.status_code == 429:\n",
    "            time.sleep(2 * (2 ** attempt))\n",
    "            continue\n",
    "\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "\n",
    "        status = str(data.get(\"status\", \"\"))\n",
    "        result = data.get(\"result\", \"\")\n",
    "\n",
    "        if status == \"0\" and \"rate limit\" in str(result).lower():\n",
    "            time.sleep(2 * (2 ** attempt))\n",
    "            continue\n",
    "\n",
    "        time.sleep(base_sleep)\n",
    "        return data\n",
    "\n",
    "    raise Exception(\"Etherscan repeatedly failed (rate limit or network).\")\n",
    "\n",
    "\n",
    "# ---- Contract verification ----\n",
    "def check_contract_verified(contract_address):\n",
    "    \"\"\"\n",
    "    Returns (verified: bool, note: str)\n",
    "    \"\"\"\n",
    "    data = es_get({\n",
    "        \"module\": \"contract\",\n",
    "        \"action\": \"getsourcecode\",\n",
    "        \"address\": contract_address\n",
    "    })\n",
    "\n",
    "    result = data.get(\"result\")\n",
    "\n",
    "    if isinstance(result, str):\n",
    "        return False, result\n",
    "\n",
    "    if not isinstance(result, list) or len(result) == 0:\n",
    "        return False, \"No source code info returned\"\n",
    "\n",
    "    src = result[0].get(\"SourceCode\", \"\")\n",
    "    verified = src is not None and str(src).strip() != \"\"\n",
    "\n",
    "    return verified, \"\"\n",
    "\n",
    "\n",
    "# ---- Fetch recent ERC20 transfers (paginated) ----\n",
    "def fetch_tokentx_recent_pages(contract_address, pages=5, offset=1000, sort=\"desc\"):\n",
    "    \"\"\"\n",
    "    Pull up to pages * offset most recent ERC20 transfers\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    notes = []\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        data = es_get({\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"tokentx\",\n",
    "            \"contractaddress\": contract_address,\n",
    "            \"page\": page,\n",
    "            \"offset\": offset,\n",
    "            \"sort\": sort\n",
    "        })\n",
    "\n",
    "        status = str(data.get(\"status\"))\n",
    "        result = data.get(\"result\")\n",
    "\n",
    "        if status == \"0\":\n",
    "            msg = str(result)\n",
    "            if \"No transactions found\" in msg:\n",
    "                break\n",
    "            notes.append(msg)\n",
    "            break\n",
    "\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            all_rows.extend(result)\n",
    "            if len(result) < offset:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return all_rows, \" | \".join(notes)\n",
    "\n",
    "\n",
    "def activity_distribution_features_recent(contract_address, pages=5, offset=1000):\n",
    "    rows, note = fetch_tokentx_recent_pages(\n",
    "        contract_address,\n",
    "        pages=pages,\n",
    "        offset=offset,\n",
    "        sort=\"desc\"\n",
    "    )\n",
    "\n",
    "    if not rows:\n",
    "        return {\n",
    "            \"tx_sampled\": 0,\n",
    "            \"unique_senders\": 0,\n",
    "            \"unique_receivers\": 0,\n",
    "            \"unique_addresses\": 0,\n",
    "            \"top10_sender_share\": np.nan,\n",
    "            \"top10_receiver_share\": np.nan,\n",
    "            \"note\": note or \"No transfers returned\"\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    sender_counts = df[\"from\"].value_counts()\n",
    "    receiver_counts = df[\"to\"].value_counts()\n",
    "\n",
    "    return {\n",
    "        \"tx_sampled\": int(len(df)),\n",
    "        \"unique_senders\": int(df[\"from\"].nunique()),\n",
    "        \"unique_receivers\": int(df[\"to\"].nunique()),\n",
    "        \"unique_addresses\": int(pd.concat([df[\"from\"], df[\"to\"]]).nunique()),\n",
    "        \"top10_sender_share\": float(sender_counts.head(10).sum() / sender_counts.sum())\n",
    "            if sender_counts.sum() else np.nan,\n",
    "        \"top10_receiver_share\": float(receiver_counts.head(10).sum() / receiver_counts.sum())\n",
    "            if receiver_counts.sum() else np.nan,\n",
    "        \"note\": note\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827e18b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tx_sampled': 5000,\n",
       " 'unique_senders': 860,\n",
       " 'unique_receivers': 1083,\n",
       " 'unique_addresses': 1309,\n",
       " 'top10_sender_share': 0.4282,\n",
       " 'top10_receiver_share': 0.4318,\n",
       " 'note': ''}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr = tm.loc[0, \"contract_address\"]\n",
    "activity_distribution_features_recent(addr, pages=5, offset=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b59f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  coingecko_id token_name symbol                            contract_address  \\\n",
       " 0      uniswap    Uniswap    UNI  0x1f9840a85d5af5bf1d1762f925bdaddc4201f984   \n",
       " 1    chainlink  Chainlink   LINK  0x514910771af9ca656af840dff83e8264ecf986ca   \n",
       " 2         aave       Aave   AAVE  0x7fc66500c84a76ad7e9c93437bfc5ac33e2ddae9   \n",
       " 3        maker      Maker    MKR  0x9f8f72aa9304c8b593d555f12ef6589cc3a579a2   \n",
       " 4     lido-dao   Lido Dao    LDO  0x5a98fcbea516cf06857215779fd812ca3bef1b32   \n",
       " \n",
       "   tier                     category     chain  verified_contract verify_note  \\\n",
       " 0    A                          DEX  ethereum               True               \n",
       " 1    A  Infrastructure & Middleware  ethereum               True               \n",
       " 2    A          Lending & Borrowing  ethereum               True               \n",
       " 3    A          Lending & Borrowing  ethereum               True               \n",
       " 4    A               Liquid staking  ethereum               True               \n",
       " \n",
       "    tx_sampled  unique_senders  unique_receivers  unique_addresses  \\\n",
       " 0        5000             854              1077              1302   \n",
       " 1        5000            1385              1582              1994   \n",
       " 2        5000             838               932              1129   \n",
       " 3        5000            1470               332              1554   \n",
       " 4        5000             744               904              1075   \n",
       " \n",
       "    top10_sender_share  top10_receiver_share note  \n",
       " 0              0.4290                0.4324       \n",
       " 1              0.2214                0.2182       \n",
       " 2              0.3118                0.3332       \n",
       " 3              0.3444                0.6560       \n",
       " 4              0.5074                0.5104       ,\n",
       " Empty DataFrame\n",
       " Columns: []\n",
       " Index: [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# Build Distribution MVP Dataset\n",
    "# ===============================\n",
    "\n",
    "results = []\n",
    "run_errors = []\n",
    "\n",
    "for _, row in tm.iterrows():\n",
    "    cid = str(row[\"coingecko_id\"]).strip()\n",
    "    name = row[\"token_name\"]\n",
    "    sym = row[\"symbol\"]\n",
    "    addr = str(row[\"contract_address\"]).strip()\n",
    "\n",
    "    record = {\n",
    "        \"coingecko_id\": cid,\n",
    "        \"token_name\": name,\n",
    "        \"symbol\": sym,\n",
    "        \"contract_address\": addr,\n",
    "        \"tier\": row.get(\"tier\", \"\"),\n",
    "        \"category\": row.get(\"category\", \"\"),\n",
    "        \"chain\": row.get(\"chain\", \"\")\n",
    "    }\n",
    "\n",
    "    # Skip invalid addresses safely\n",
    "    if not is_valid_eth_address(addr):\n",
    "        record.update({\n",
    "            \"verified_contract\": np.nan,\n",
    "            \"verify_note\": \"Missing/invalid contract address\",\n",
    "            \"tx_sampled\": np.nan,\n",
    "            \"unique_senders\": np.nan,\n",
    "            \"unique_receivers\": np.nan,\n",
    "            \"unique_addresses\": np.nan,\n",
    "            \"top10_sender_share\": np.nan,\n",
    "            \"top10_receiver_share\": np.nan,\n",
    "            \"note\": \"Skipped\"\n",
    "        })\n",
    "        results.append(record)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        verified, verify_note = check_contract_verified(addr)\n",
    "        feats = activity_distribution_features_recent(\n",
    "            addr,\n",
    "            pages=5,        # 5000 tx window\n",
    "            offset=1000\n",
    "        )\n",
    "\n",
    "        record.update({\n",
    "            \"verified_contract\": bool(verified),\n",
    "            \"verify_note\": verify_note,\n",
    "            **feats\n",
    "        })\n",
    "        results.append(record)\n",
    "\n",
    "    except Exception as e:\n",
    "        record.update({\n",
    "            \"verified_contract\": np.nan,\n",
    "            \"verify_note\": \"Error during Etherscan pull\",\n",
    "            \"tx_sampled\": np.nan,\n",
    "            \"unique_senders\": np.nan,\n",
    "            \"unique_receivers\": np.nan,\n",
    "            \"unique_addresses\": np.nan,\n",
    "            \"top10_sender_share\": np.nan,\n",
    "            \"top10_receiver_share\": np.nan,\n",
    "            \"note\": str(e)\n",
    "        })\n",
    "        results.append(record)\n",
    "        run_errors.append({\"coingecko_id\": cid, \"error\": str(e)})\n",
    "\n",
    "# Build DataFrame\n",
    "dist_mvp = pd.DataFrame(results)\n",
    "\n",
    "dist_mvp.head(), pd.DataFrame(run_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99325b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      20.0\n",
       "mean     5000.0\n",
       "std         0.0\n",
       "min      5000.0\n",
       "25%      5000.0\n",
       "50%      5000.0\n",
       "75%      5000.0\n",
       "max      5000.0\n",
       "Name: tx_sampled, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the big loop\n",
    "dist_mvp = pd.DataFrame(results)\n",
    "\n",
    "dist_mvp[\"tx_sampled\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01771697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/processed/distribution_mvp_etherscan.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "dist_mvp.to_csv(\"data/processed/distribution_mvp_etherscan.csv\", index=False)\n",
    "\"data/processed/distribution_mvp_etherscan.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72ad98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
